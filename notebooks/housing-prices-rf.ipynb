{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:55:26.490227Z","iopub.execute_input":"2025-08-18T18:55:26.491040Z","iopub.status.idle":"2025-08-18T18:55:26.509169Z","shell.execute_reply.started":"2025-08-18T18:55:26.491015Z","shell.execute_reply":"2025-08-18T18:55:26.508317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 0: Imports & Setup\n# =========================\nimport os\nimport numpy as np\nimport pandas as pd\n\nfrom scipy.stats import skew\nfrom pathlib import Path\n\n# paths (Kaggle default)\nDATA_DIR = Path(\"/kaggle/input/house-prices-advanced-regression-techniques\")\nOUT_DIR = Path(\"/kaggle/working\")\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\npd.set_option(\"display.max_columns\", 120)\npd.set_option(\"display.width\", 120)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:55:26.510587Z","iopub.execute_input":"2025-08-18T18:55:26.510919Z","iopub.status.idle":"2025-08-18T18:55:26.516946Z","shell.execute_reply.started":"2025-08-18T18:55:26.510893Z","shell.execute_reply":"2025-08-18T18:55:26.516091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 1: Load raw data\n# =========================\ntrain = pd.read_csv(DATA_DIR / \"train.csv\")\ntest = pd.read_csv(DATA_DIR / \"test.csv\")\n\nprint(train.shape, test.shape)\ntrain.head(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 2: Combine for uniform cleaning\n# (keep a flag to split later)\n# =========================\ntrain['__is_train'] = 1\ntest['__is_train'] = 0\nfull = pd.concat([train, test], axis=0, ignore_index=True)\nprint(full.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 3: Quick missingness snapshot\n# =========================\nmiss = full.isna().mean().sort_values(ascending=False)\nmiss[miss > 0].head(20)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 4: Fix data types (categorical vs ordinal vs numeric)\n# - Many \"numbers\" are actually categories (e.g., MSSubClass, MoSold)\n# =========================\n# treat as categorical strings\ncat_as_num = [\"MSSubClass\", \"MoSold\", \"YrSold\"]\nfull[cat_as_num] = full[cat_as_num].astype(str)\n\n# Ordinal quality maps (Ex>Gd>TA>Fa>Po). Include None->0 for convenience.\nqual_map = {\"Ex\":5, \"Gd\":4, \"TA\":3, \"Fa\":2, \"Po\":1, np.nan:0}\n\nfor col in [\"ExterQual\",\"ExterCond\",\"BsmtQual\",\"BsmtCond\",\"HeatingQC\",\n            \"KitchenQual\",\"FireplaceQu\",\"GarageQual\",\"GarageCond\",\"PoolQC\"]:\n    full[col] = full[col].map(qual_map).astype(\"Int64\")\n\n# Basement exposure & finish types (custom ordinal encodings)\nbsmt_exp_map = {\"Gd\":4, \"Av\":3, \"Mn\":2, \"No\":1, np.nan:0}\nfor col in [\"BsmtExposure\"]:\n    full[col] = full[col].map(bsmt_exp_map).astype(\"Int64\")\n\nbsmt_fin_map = {\"GLQ\":6,\"ALQ\":5,\"BLQ\":4,\"Rec\":3,\"LwQ\":2,\"Unf\":1, np.nan:0}\nfor col in [\"BsmtFinType1\",\"BsmtFinType2\"]:\n    full[col] = full[col].map(bsmt_fin_map).astype(\"Int64\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# NA means \"None\" (feature absent)\nnone_fill = [\"Alley\",\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\n             \"FireplaceQu\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\",\n             \"PoolQC\",\"Fence\",\"MiscFeature\",\"MasVnrType\"]\nfor col in none_fill:\n    if col in full.columns:\n        full[col] = full[col].fillna(\"None\")\n\n# Garage numerics: NA -> 0\nfor col in [\"GarageYrBlt\",\"GarageArea\",\"GarageCars\"]:\n    if col in full.columns:\n        full[col] = full[col].fillna(0)\n\n# Masonry veneer area: NA -> 0\nif \"MasVnrArea\" in full.columns:\n    full[\"MasVnrArea\"] = full[\"MasVnrArea\"].fillna(0)\n\n# LotFrontage by neighborhood median\nif \"LotFrontage\" in full.columns and \"Neighborhood\" in full.columns:\n    full[\"LotFrontage\"] = full.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n        lambda s: s.fillna(s.median())\n    )\n\n# Functional: NA -> Typ\nif \"Functional\" in full.columns:\n    full[\"Functional\"] = full[\"Functional\"].fillna(\"Typ\")\n\n# Mode fills for a few mostly-complete categoricals\nfor col in [\"MSZoning\",\"Electrical\",\"KitchenQual\",\"Exterior1st\",\"Exterior2nd\",\"SaleType\",\"Utilities\"]:\n    if col in full.columns and full[col].isna().any():\n        full[col] = full[col].fillna(full[col].mode()[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Totals\nfull[\"TotalSF\"] = full.get(\"1stFlrSF\",0) + full.get(\"2ndFlrSF\",0) + full.get(\"TotalBsmtSF\",0)\nfull[\"TotalBath\"] = (\n    full.get(\"FullBath\",0) + 0.5*full.get(\"HalfBath\",0) +\n    full.get(\"BsmtFullBath\",0) + 0.5*full.get(\"BsmtHalfBath\",0)\n)\n\n# Flags\nfull[\"HasPool\"] = (full.get(\"PoolArea\",0) > 0).astype(int)\nfull[\"HasGarage\"] = (full.get(\"GarageArea\",0) > 0).astype(int)\nfull[\"HasFireplace\"] = (full.get(\"Fireplaces\",0) > 0).astype(int)\nfull[\"HasBasement\"] = (full.get(\"TotalBsmtSF\",0) > 0).astype(int)\n\n# Ages\nif {\"YrSold\",\"YearBuilt\"}.issubset(full.columns):\n    full[\"HouseAge\"] = full[\"YrSold\"].astype(int) - full[\"YearBuilt\"].astype(int)\nif {\"YrSold\",\"YearRemodAdd\"}.issubset(full.columns):\n    full[\"RemodAge\"] = full[\"YrSold\"].astype(int) - full[\"YearRemodAdd\"].astype(int)\nif \"GarageYrBlt\" in full.columns and \"YrSold\" in full.columns:\n    full[\"GarageAge\"] = np.where(full[\"GarageYrBlt\"]>0,\n                                 full[\"YrSold\"].astype(int)-full[\"GarageYrBlt\"].astype(int),\n                                 -1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 6: Context-aware imputations\n# =========================\n# LotFrontage: impute by Neighborhood median\nif \"LotFrontage\" in full.columns:\n    full[\"LotFrontage\"] = full.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n        lambda s: s.fillna(s.median())\n    )\n\n# Functional: NA -> Typ\nif \"Functional\" in full.columns:\n    full[\"Functional\"] = full[\"Functional\"].fillna(\"Typ\")\n\n# Mode fills for a few mostly-complete categoricals\nfor col in [\"MSZoning\",\"Electrical\",\"KitchenQual\",\"Exterior1st\",\"Exterior2nd\",\"SaleType\",\"Utilities\"]:\n    if col in full.columns and full[col].isna().any():\n        full[col] = full[col].fillna(full[col].mode()[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 7: Feature engineering (tidy + useful combos)\n# =========================\n# Total square footage including basement\nfull[\"TotalSF\"] = full.get(\"1stFlrSF\",0) + full.get(\"2ndFlrSF\",0) + full.get(\"TotalBsmtSF\",0)\n\n# Total baths (weighted half baths)\nfull[\"TotalBath\"] = (\n    full.get(\"FullBath\",0) + 0.5*full.get(\"HalfBath\",0) +\n    full.get(\"BsmtFullBath\",0) + 0.5*full.get(\"BsmtHalfBath\",0)\n)\n\n# Has flags\nfull[\"HasPool\"] = (full.get(\"PoolArea\",0) > 0).astype(int)\nfull[\"HasGarage\"] = (full.get(\"GarageArea\",0) > 0).astype(int)\nfull[\"HasFireplace\"] = (full.get(\"Fireplaces\",0) > 0).astype(int)\nfull[\"HasBasement\"] = (full.get(\"TotalBsmtSF\",0) > 0).astype(int)\n\n# Age features\nfull[\"HouseAge\"] = full[\"YrSold\"].astype(int) - full[\"YearBuilt\"].astype(int)\nfull[\"RemodAge\"] = full[\"YrSold\"].astype(int) - full[\"YearRemodAdd\"].astype(int)\nfull[\"GarageAge\"] = np.where(full[\"GarageYrBlt\"]>0, full[\"YrSold\"].astype(int)-full[\"GarageYrBlt\"].astype(int), -1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 8: Rare category consolidation\n# - Collapse very small levels to \"Other\" to reduce one-hot sparsity\n# =========================\ndef collapse_rare_categories(series, min_count=10, other_label=\"Other\"):\n    vc = series.value_counts(dropna=False)\n    rare = vc[vc < min_count].index\n    return series.where(~series.isin(rare), other_label)\n\ncat_cols = full.select_dtypes(include=[\"object\"]).columns.tolist()\nfor col in cat_cols:\n    full[col] = collapse_rare_categories(full[col], min_count=10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 9: Drop nearly-constant/unhelpful cols (optional)\n# =========================\nto_drop = []\nif \"Utilities\" in full.columns and full[\"Utilities\"].nunique() == 1:\n    to_drop.append(\"Utilities\") # almost always 'AllPub'\n# (Optionally drop highly collinear duplicates later for linear models)\nfull = full.drop(columns=to_drop)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 10: Handle obvious outliers (train only)\n# - Common heuristic: remove huge GrLivArea with suspiciously low SalePrice\n# =========================\n# We'll mark them now and actually remove after we split back to train.\nfull[\"_outlier_flag\"] = 0\nif \"GrLivArea\" in full.columns and \"SalePrice\" in full.columns:\n    mask_out = (full[\"__is_train\"]==1) & (full[\"GrLivArea\"]>4000) & (full[\"SalePrice\"]<300000)\n    full.loc[mask_out, \"_outlier_flag\"] = 1\nfull[\"_outlier_flag\"].value_counts()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 11: Transform skewed numeric features (log1p)\n# - Do NOT transform target here; that belongs in modeling.\n# =========================\nnumeric_cols = full.select_dtypes(include=[np.number]).columns.tolist()\n# exclude target and helper columns\nexclude = {\"SalePrice\",\"Id\",\"__is_train\",\"_outlier_flag\",\"GarageYrBlt\"}\nnum_feats = [c for c in numeric_cols if c not in exclude]\n\nskews = full[num_feats].apply(lambda s: skew(s.dropna())).sort_values(ascending=False)\nskewed = skews[skews > 0.75].index.tolist()\n\n# log1p transform skewed positive features (avoid negatives)\nfor col in skewed:\n    # shift if needed to ensure positivity\n    min_val = full[col].min()\n    if pd.notna(min_val) and min_val <= 0:\n        full[col] = full[col] - min_val + 1\n    full[col] = np.log1p(full[col])\n    \nskews.head(10), len(skewed)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 12: One-hot encode remaining categoricals\n# =========================\ncat_cols = full.select_dtypes(include=[\"object\"]).columns.tolist()\nfull_encoded = pd.get_dummies(full, columns=cat_cols, drop_first=False)\nfull_encoded.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 13: Split back to train/test, drop outliers from train\n# =========================\ntrain_clean = full_encoded[full_encoded[\"__is_train\"]==1].copy()\ntest_clean = full_encoded[full_encoded[\"__is_train\"]==0].copy()\n\n# drop helper cols\nfor c in [\"__is_train\"]:\n    if c in train_clean.columns: train_clean = train_clean.drop(columns=[c])\n    if c in test_clean.columns: test_clean = test_clean.drop(columns=[c])\n\n# remove marked outliers from training set\ntrain_clean = train_clean[train_clean[\"_outlier_flag\"]==0].copy()\ntrain_clean = train_clean.drop(columns=[\"_outlier_flag\"])\nif \"_outlier_flag\" in test_clean.columns:\n    test_clean = test_clean.drop(columns=[\"_outlier_flag\"])\n\nprint(train_clean.shape, test_clean.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 14: Align columns (ensure test has same cols)\n# =========================\n# Align columns so X_train and X_test match (excluding SalePrice)\ny = train_clean[\"SalePrice\"].copy()\nX = train_clean.drop(columns=[\"SalePrice\"])\nX_test = test_clean.drop(columns=[\"SalePrice\"]) if \"SalePrice\" in test_clean.columns else test_clean.copy()\n\nX, X_test = X.align(X_test, join=\"left\", axis=1, fill_value=0)\nX.shape, X_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =========================\n# Cell 15: Save cleaned outputs for modeling\n# =========================\nX.to_csv(OUT_DIR / \"train_features_clean.csv\", index=False)\ny.to_csv(OUT_DIR / \"train_target.csv\", index=False)\nX_test.to_csv(OUT_DIR / \"test_features_clean.csv\", index=False)\n\nprint(\"Saved to /kaggle/working:\")\nlist(OUT_DIR.iterdir())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\nIN_KAGGLE = Path(\"/kaggle/working\").exists()\n\nif IN_KAGGLE:\n    PROC_DIR = Path(\"/kaggle/working\")  # where you saved the cleaned files in Kaggle\n    RAW_DIR  = Path(\"/kaggle/input/house-prices-advanced-regression-techniques\")\nelse:\n    BASE    = Path(r\"C:\\Users\\rcoul\\Downloads\\Housing_Prices_Model\\Data\")\n    PROC_DIR = BASE / \"Processed\"\n    RAW_DIR  = BASE / \"Raw\"\n\nprint(\"PROC_DIR:\", PROC_DIR)\nprint(\"RAW_DIR :\", RAW_DIR)\n\n# ---- Load processed features/target ----\nX_train = pd.read_csv(PROC_DIR / \"train_features_clean.csv\")\ny_train = pd.read_csv(PROC_DIR / \"train_target.csv\").squeeze(\"columns\")\nX_test  = pd.read_csv(PROC_DIR / \"test_features_clean.csv\")\n\n# ---- Baseline model + CV ----\nfrom sklearn.impute import SimpleImputer\nimport numpy as np\n\n# Impute missing values with median (better for skewed numeric data)\nimputer = SimpleImputer(strategy=\"median\")\n\nX_train_imputed = imputer.fit_transform(X_train)\nX_test_imputed = imputer.transform(X_test)\n\n# Refit the model using imputed data\nmodel = RandomForestRegressor(n_estimators=200, random_state=42)\n\ncv = cross_val_score(model, X_train_imputed, y_train, cv=5, scoring=\"neg_root_mean_squared_error\")\nprint(\"CV RMSE:\", -cv.mean())\n\nmodel.fit(X_train_imputed, y_train)\npreds = model.predict(X_test_imputed)\n\n# ---- Build submission from the official sample ----\nsample = pd.read_csv(RAW_DIR / \"sample_submission.csv\")\nsample[\"SalePrice\"] = preds\n\n# Save submission to the right place\nsub_path = (PROC_DIR / \"submission.csv\")  # this is /kaggle/working/submission.csv in Kaggle\nsample.to_csv(sub_path, index=False)\nprint(\"Wrote submission to:\", sub_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T18:57:53.252319Z","iopub.execute_input":"2025-08-18T18:57:53.252629Z","iopub.status.idle":"2025-08-18T18:58:30.176389Z","shell.execute_reply.started":"2025-08-18T18:57:53.252609Z","shell.execute_reply":"2025-08-18T18:58:30.175577Z"}},"outputs":[],"execution_count":null}]}