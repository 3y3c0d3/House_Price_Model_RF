##ğŸŒ² House Prices Prediction with Random Forest

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Libraries](https://img.shields.io/badge/Libraries-ScikitLearn%20%7C%20Pandas%20%7C%20NumPy-orange.svg)
![Competition](https://img.shields.io/badge/Kaggle-House%20Prices%20Competition-blueviolet.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

This project uses a **Random Forest Regressor** to predict house prices for the Kaggle competition **House Prices - Advanced Regression Techniques**.  
It demonstrates how to build an **end-to-end machine learning workflow** with data cleaning, feature engineering, and evaluation.  

---

## ğŸ“‚ Project Structure

house-prices-random-forest/ â”‚â”€â”€ data/ â”‚ â”œâ”€â”€ train.csv # Raw training data (from Kaggle) â”‚ â”œâ”€â”€ test.csv # Raw test data (from Kaggle) â”‚ â”œâ”€â”€ train_features_clean.csv # Cleaned training features â”‚ â”œâ”€â”€ test_features_clean.csv # Cleaned test features â”‚ â””â”€â”€ train_target.csv # Target variable (SalePrice) â”‚ â”‚â”€â”€ notebooks/ â”‚ â””â”€â”€ housing_prices_randomforest.ipynb # Kaggle Notebook / Jupyter Notebook â”‚ â”‚â”€â”€ scripts/ â”‚ â””â”€â”€ Housing_Prices_RF_Model.py # Python script version of pipeline â”‚  â”‚â”€â”€ README.md # Project documentation

---

## âš™ï¸ Workflow

1. **Data Cleaning**  
   - Filled missing values (median for numeric, mode for categorical).  
   - Encoded categorical features with OneHotEncoder.  

2. **Feature Engineering**  
   - Separated categorical and numeric features.  
   - Built preprocessing pipeline with `ColumnTransformer`.  

3. **Modeling**  
   - Random Forest Regressor (`RandomForestRegressor`) with:  
     - `n_estimators=200`  
     - `max_depth=None` (allow full growth)  
     - `random_state=42`  

4. **Evaluation**  
   - Metric: Root Mean Squared Log Error (RMSLE).  
   - Cross-Validation RMSE achieved: **~0.138** (baseline improvement).  
   - Kaggle Private Leaderboard Score: **0.14x**.  

---

## ğŸ“Š Results

- âœ… Strong baseline model without heavy tuning.  
- âœ… Showed improvement over Linear Regression baseline.  
- âœ… Served as a foundation before advancing to **XGBoost**.  

---

## ğŸš€ How to Reproduce

Clone this repository and run:

```bash
git clone https://github.com/<your-username>/house-prices-random-forest.git
cd house-prices-random-forest
pip install -r requirements.txt
python scripts/Housing_Prices_RF_Model.py

Or open the Kaggle Notebook directly and rerun all cells.


```

## ğŸ› ï¸ Tech Stack

Python (3.9+)

Pandas / NumPy â€“ data manipulation

Scikit-Learn â€“ Random Forest, pipelines, preprocessing

Matplotlib / Seaborn â€“ visualizations



---

## ğŸ“Œ Acknowledgements

Dataset: Kaggle House Prices Competition

Inspired by top Kaggle kernels and community notebooks.



---

## âœ¨ Author

ğŸ‘¤ Ryan Coulter
ğŸ”— GitHub | Kaggle | LinkedIn
